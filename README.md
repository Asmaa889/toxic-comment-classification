# toxic-comment-classification
detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspectiveâ€™s current models.
kaggle comptition https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/overview

# preprocessing dataset
- removed urls, username, contractions and non-English words.
- used tokenizers to convert the words in the corpus to index values in dict.
- padded the sequence using padding="post".

# bulit bi-directional lstm followed by 2 dense layers.
